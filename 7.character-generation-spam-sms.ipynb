{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation (SPAM SMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to use PyTorch and Recurrent Neural Networks generate some Spam SMS messages. The model works on the character level because SMS data contains a lot of abbreviated and slang texts that we want to keep. You can see in the sample text shown below that the word *tkts* is used to refer to tickets.So if we don't use the character level model we will discard these non standard words and we wont be able to properly learn the dataset.\n",
    "\n",
    "The data that we are using can be downloaded from [here](http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)\n",
    "First let's load the SPAM data from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to \""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[line.replace('spam\\t',' ').strip() for line in open('data/spam.txt').readlines() if line.startswith('spam')]\n",
    "text=' '.join(text)\n",
    "text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is built our character dictionary of characters available in our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 94\n"
     ]
    }
   ],
   "source": [
    "characters=list(set(text))\n",
    "index2char=dict(enumerate(characters))\n",
    "char2index={c:i for i,c in enumerate(characters)}\n",
    "print('Number of unique characters:',len(characters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling training data from text\n",
    "Next we are gonna write a small function to randomly selects a small part for the text and returns it to us.We pass the length and get a text with that size back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(text, sample_length=20):\n",
    "    start_index=random.randint(0,len(text)-sample_length)\n",
    "    return text[start_index:start_index+sample_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"your friend 1/1 For ur chance to win £250 cash every wk TXT: PLAY to 83370. T's&C's www.music-trivia.net custcare 08715705022, 1x150p/wk. Final Chance! Claim ur £150 worth of discount vouchers today! Text YES to 85023 now! SavaMob, member offers mobile! T Cs SavaMob POBOX84, M263UZ. £3.00 Subs 16 Sp\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample(text,sample_length=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "Now we need to perform a one hot encoding of the sample text to be able to feed it into our model. Here is a small utility function that receives a sample text and \n",
    "performs a one hot encoding of its characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sample_text):\n",
    "    one_hot=torch.zeros(len(sample_text),len(characters))\n",
    "    for i,character in enumerate(sample_text):\n",
    "        one_hot[i][char2index[character]]=1\n",
    "    return one_hot    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encode('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Input and target sets\n",
    "For each character in the sample text, we get a single character as a training and get the next character as target. Essentially model receives one character as an input and predicts one character as output. To avoid looping through the sample text characters one by one, we create a batch of (Character, Next character) and then pass all of them at once to the network to get the prediction for all of them. We will then use these predictions to calculate the loss.\n",
    "for Example :\n",
    "\n",
    "Text = **ABCDEFGHIJKLMNOPQRSTUVWXYZ**\n",
    "\n",
    "sample_text = **GHIJKLMNOP**                 #length=10\n",
    "\n",
    "sample_text[:-1]  ->  inputs  =  **GHIJKLMNO**\n",
    "\n",
    "sample_text[1: ]  ->  targets =   **HIJKLMNOP**\n",
    "\n",
    "We can create our inputs an targets sets by simply shifting the sample text. Essentially omitting the last character for to get the inputs vector and omitting the first character to get the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_data(text,sample_length=20):\n",
    "    \"\"\"returns the inputs and targets for a sample text\"\"\"\n",
    "    sample_text=random_sample(text,sample_length)\n",
    "    inputs=sample_text[:-1]\n",
    "    targets=sample_text[1:]\n",
    "    one_hot_inputs=one_hot_encode(inputs)\n",
    "    target_indexes=torch.LongTensor([char2index[character] for character in targets])\n",
    "    return one_hot_inputs,target_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Here we define a very simple network model. We have one GRU for encoding the relation between the input characters and one simple linear layer to project the hidden size to our character size ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamGRU(nn.Module):\n",
    "    def __init__(self,character_size,hidden_size):\n",
    "        super(SpamGRU,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.gru=nn.GRU(character_size,hidden_size,batch_first=True)\n",
    "        self.charMapper=nn.Linear(hidden_size,character_size)\n",
    "    def forward(self,inputs,hidden):\n",
    "        out,hidden=self.gru(inputs,hidden)\n",
    "        logits=self.charMapper(out)\n",
    "        return logits, hidden\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SpamGRU(len(characters),128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,text,training_steps=5000,sample_length=50,lr=0.005):\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    for step in range(training_steps+1):\n",
    "        optimizer.zero_grad() \n",
    "        inputs ,targets=random_training_data(text,sample_length)\n",
    "        hidden=model.init_hidden()\n",
    "        outputs,_=model(inputs.unsqueeze(0),hidden)\n",
    "        loss=F.cross_entropy(outputs.squeeze(0),targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step%200==0:\n",
    "            print(f'Step:{step} ({step*100/training_steps:.1f}%)  Loss:{loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0 (0.0%)  Loss:1.3637193441390991\n",
      "Step:200 (4.0%)  Loss:1.407169222831726\n",
      "Step:400 (8.0%)  Loss:1.8686273097991943\n",
      "Step:600 (12.0%)  Loss:0.8712431192398071\n",
      "Step:800 (16.0%)  Loss:1.2440128326416016\n",
      "Step:1000 (20.0%)  Loss:2.254335403442383\n",
      "Step:1200 (24.0%)  Loss:1.6136444807052612\n",
      "Step:1400 (28.0%)  Loss:1.9385374784469604\n",
      "Step:1600 (32.0%)  Loss:0.9153338074684143\n",
      "Step:1800 (36.0%)  Loss:1.354489803314209\n",
      "Step:2000 (40.0%)  Loss:1.1856731176376343\n",
      "Step:2200 (44.0%)  Loss:1.6169809103012085\n",
      "Step:2400 (48.0%)  Loss:1.6817787885665894\n",
      "Step:2600 (52.0%)  Loss:1.7164816856384277\n",
      "Step:2800 (56.0%)  Loss:1.7623902559280396\n",
      "Step:3000 (60.0%)  Loss:1.613673210144043\n",
      "Step:3200 (64.0%)  Loss:1.054235816001892\n",
      "Step:3400 (68.0%)  Loss:1.1988729238510132\n",
      "Step:3600 (72.0%)  Loss:1.80231773853302\n",
      "Step:3800 (76.0%)  Loss:1.6044071912765503\n",
      "Step:4000 (80.0%)  Loss:2.095244884490967\n",
      "Step:4200 (84.0%)  Loss:1.912640929222107\n",
      "Step:4400 (88.0%)  Loss:1.733980417251587\n",
      "Step:4600 (92.0%)  Loss:1.9005563259124756\n",
      "Step:4800 (96.0%)  Loss:1.8307029008865356\n",
      "Step:5000 (100.0%)  Loss:1.0846645832061768\n"
     ]
    }
   ],
   "source": [
    "train(model,text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Text\n",
    "We do not simply choose the index with the highest probability to have more variety in our predicted character. To that we use the Numpy choice function to selected a character index based on their predicted probabilities by the network. we can also use the torch.multinomial() for the sampling, which essentially does the same thing.\n",
    "\n",
    "Another thing to note is that, passing a hidden state of zeros does not provide a helpful initial context to the model for text generation. We can help the network to have a better initial hidden state by providing a few set of starting characters and create a hidden state from these characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model,starting_text='',desired_length=20, temperature=0.8):\n",
    "    #Creating initial hidden state\n",
    "    inputs=one_hot_encode(starting_text)\n",
    "    hidden=model.init_hidden()\n",
    "    for i in range(inputs.size(0)):\n",
    "        out, hidden=model(inputs[i].view(-1,1,inputs[i].size(-1)),hidden)\n",
    "    inputs=out\n",
    "    generated_characters=''\n",
    "    #generating characters\n",
    "    for i in range(desired_length):\n",
    "        outs,hidden =model(inputs,hidden)\n",
    "        prob=F.softmax(outs/temperature,dim=2)\n",
    "        character_index=np.random.choice(len(characters),1,p=prob.data.flatten().numpy())\n",
    "        character=index2char[character_index.item()]\n",
    "        generated_characters+=character\n",
    "        inputs=one_hot_encode(character).unsqueeze(0)\n",
    "    return starting_text+' '+generated_characters\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get a free nd of a £100 prize Games accout the latest from a £2000 prize. To claim call 08000930705 from land line or of Colour from 2004, MUST GO to 8007 Get to receive a £100 prize GUARANTEED Call 090663622066'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geenrated_text=generate(model,starting_text='get a free', temperature=0.3, desired_length=200)\n",
    "geenrated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get a free nd call 08000839402 or call 0906636220116+ Gr8 from a charged 4. Customer service reply to receive a £500 prize. To claim your mobile number service reply to receive a £500 prize. Gement for your free'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(model,starting_text='get a free', temperature=0.3, desired_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, using the sampling technique instead of simply choosing the character with highest output value, results in creating a variety in our generated response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
