{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dummy sequence, You can assume these are indexes of our words.\n",
    "The objective of the whole process is to make a variable-length sequence suitable to be fed into an RNN(LSTM, GRU, etc) layer.\n",
    "Here are the steps:\n",
    "\n",
    "1. Create a variable-length sequence.\n",
    "2. Pad the sequences to make them of the same length\n",
    "3. Create an embedding for them.\n",
    "4. Pack the embeddings (to speedup the RNN calculations)\n",
    "5. Feed the (now packed) embeddings to LSTM to get outputs\n",
    "\n",
    "To achieve the goal, we are going to use two utility functions from PyTorch. \n",
    "\n",
    "- **pad_packed_sequence** (Add zeros to the sequences so that they all have the same size)\n",
    "- **pack_padded_sequence** ( Not necessarily required, but to be able to use GPU more efficiently and speed up the RNN calculations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5], [6, 7, 8, 9, 10]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [   \n",
    "    [1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8, 9,10]\n",
    "]\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to store the length of each sequence before attempting to do any paddings.\n",
    "We need these lengths so that later on, we know exactly how to pack them and get rid of extra zeros in each sequence.\n",
    "This way we don't have to do additional calculations on some useless zeros(pad values) and this will speed up our RNN calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths=torch.LongTensor([len(sequence) for sequence in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(num_embeddings=11, embedding_dim=4)\n",
    "lstm = LSTM(input_size=4, hidden_size=2, batch_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  0,  0],\n",
       "        [ 4,  5,  0,  0,  0],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Padding\n",
    "sequences=[torch.LongTensor(sequence) for sequence in sequences]\n",
    "sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7392, -0.5116,  1.6044,  0.2385],\n",
       "         [ 0.0548, -0.3227,  1.1412,  1.2520],\n",
       "         [ 0.1933,  0.1486, -0.5080, -1.4867],\n",
       "         [ 0.6410, -0.8795,  0.3313,  0.6747],\n",
       "         [ 0.6410, -0.8795,  0.3313,  0.6747]],\n",
       "\n",
       "        [[ 0.7591,  2.0299, -0.5631, -0.4719],\n",
       "         [ 0.3002, -0.5866, -0.5725,  0.0149],\n",
       "         [ 0.6410, -0.8795,  0.3313,  0.6747],\n",
       "         [ 0.6410, -0.8795,  0.3313,  0.6747],\n",
       "         [ 0.6410, -0.8795,  0.3313,  0.6747]],\n",
       "\n",
       "        [[ 0.0741,  2.9282,  0.9944, -1.6001],\n",
       "         [ 0.8746,  0.2755,  0.2825,  1.8457],\n",
       "         [ 0.5073, -1.2891,  1.3445, -0.0612],\n",
       "         [ 0.1452, -1.5582, -0.1543, -1.0414],\n",
       "         [-1.4174, -0.7062, -0.4610, -1.4128]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Embedding\n",
    "sequences_embeded=embedding(sequences_padded)\n",
    "sequences_embeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0741,  2.9282,  0.9944, -1.6001],\n",
       "        [ 0.7392, -0.5116,  1.6044,  0.2385],\n",
       "        [ 0.7591,  2.0299, -0.5631, -0.4719],\n",
       "        [ 0.8746,  0.2755,  0.2825,  1.8457],\n",
       "        [ 0.0548, -0.3227,  1.1412,  1.2520],\n",
       "        [ 0.3002, -0.5866, -0.5725,  0.0149],\n",
       "        [ 0.5073, -1.2891,  1.3445, -0.0612],\n",
       "        [ 0.1933,  0.1486, -0.5080, -1.4867],\n",
       "        [ 0.1452, -1.5582, -0.1543, -1.0414],\n",
       "        [-1.4174, -0.7062, -0.4610, -1.4128]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 2, 1, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Packing\n",
    "sequences_packed = pack_padded_sequence(sequences_embeded, sequence_lengths.cpu().numpy(), batch_first=True,enforce_sorted=False)\n",
    "sequences_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0060, -0.0090],\n",
       "        [ 0.0550,  0.0006],\n",
       "        [ 0.0413, -0.0685],\n",
       "        [ 0.2042, -0.0397],\n",
       "        [ 0.1922, -0.0140],\n",
       "        [ 0.2770, -0.0185],\n",
       "        [ 0.2018, -0.0015],\n",
       "        [ 0.0879,  0.0264],\n",
       "        [ 0.1439,  0.0429],\n",
       "        [ 0.1171,  0.1591]], grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 2, 1, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM\n",
    "outputput_packed, (hidden,context)=lstm(sequences_packed)\n",
    "outputput_packed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is LSTM, *output_packed* is now is a Named Tuple which provides some additional information that we might not care about. The actual output that we want is in *data* field since we might need to use it as in input to our LSTM in the next iteration.\n",
    "We can access the data (the actual output values of LSTM) in two ways\n",
    "\n",
    "**1.Easy way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputput_packed.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also need the *hidden state* of the last layer of LSTM (context vector).Possibly for your decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Slightly more involved way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, input_sequence_sizes = pad_packed_sequence(outputput_packed, batch_first=True)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
